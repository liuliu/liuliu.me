---
layout: post
title: 行为、感知与理想模型
tags:
- 随感
status: publish
type: post
published: true
meta: {}
---
<p>这是AI研究中永远无法回避的命题。无论是做深度的模拟，例如达尔文系列，还是做表面的模拟，例如Asimo系列，开发者都潜在地选择了他们的观念，并将其带入自己的机器人中。
</p><p>问题的归结起来就是问，是否智能中存在一些先验东西，即先验的模式、模型和能力。如果认为智能中存在一些先验的部分，那么智能技术的发展就应该是多分支的，并且最后将各个分支上的发展（语音识别、语音合成、图像识别、路径规划……）综合起来构成一个智能体。如果认为智能中不存在先验的部分，那么智能技术中就存在一个大统一的技术，所有的智能研究上的实践问题都可以应用该技术得到完美解决。
</p><p>不存在先验部分的智能看起来的确很完美。就是说，智能体的知识完全取决于感官体验，而不是内部的模式。那么也就不需要对其内部模式进行设计，而只注重宏观的产生智能部分的设计。而有先验部分的智能不得不花大量的时间在巧妙的先验知识的设定上。
</p><p>但是，在完全不存在先验的智能设计上，我还摸不到法门。将该问题转换到我现在所关心的领域总是遇到一些难以克服的困难。其中一大疑问即是，单一的感知能否产生意义明确可识别的智能？关键问题是怎样识别算法是否产生了智能。具体到我的问题上，输入图像序列后，算法得出什么的结果算是具有了智能？成功找出某一物品？将图像分割为有意义的几部分？显然，这些操作都需要先验知识。这些先验知识具体到了某一物品上的特征，具体到了基础的图像操作，比如高斯-拉普拉斯算子。
</p><p>现代的生物学研究已经证实，哺乳动物看物体时存在一个类似高斯-拉普拉斯算子的卷积运算。这似乎可以说明在常见的具有智慧的动物中是存在一些先验的模式的。但是，如果按照进化论的思路，那么这种能力也应该是进化而来的。换句话说，遗传得来的能力并不代表是先验的。
</p><p>我暂时还没有能力能够做多感知的实验，还无法明确得知多感知是否能够不需要先验产生智能。现在唯一得知的是，单一感知我还无法找到一个方法能够不需要先验得到像样的结果。
</p><p>对于儿童早期认知的研究并没有排除儿童具有先验知识的这一种情况，但是研究很鼓舞人心的一点是，即使儿童具有先验知识，也是极其少量的，大量的知识来自于儿童与环境磨合过程中所得到的经验。这样的结果似乎暗示着，只要具有足够多的经验，就可以产生合适的智能。
</p><p>其实这样的问题除了求助于皮亚杰外，还取决于各人所坚持的信念。如果是一个笛卡儿一样二元世界观者，那么就会相信存在先验的理想模型。如果是一个纯粹的感知主义者，那么就会觉得一切知识来源于感官。而我更愿意相信，“有两件事物我愈是思考愈觉神奇，心中也愈充满敬畏，那就是我头顶上的星空与我内心的道德准则。”
</p><p>这也就是我现在所着手的，用尽量具有广泛意义的先验知识来得到一个可识别的结果。</p>
