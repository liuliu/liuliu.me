---
layout: post
title: Target has been Vectorized and Quantized
tags:
- Twitter
status: draft
type: post
published: false
meta:
  _edit_last: '3'
---
A common method to do computer experiment is to vectorize something and then quantize them in order to get a good, discrete representation of the essence. The one convenient thing about multimedia is that all the digital form of media is naturally a vector and sort of quantized. That's to say, to extract a better representation of media, we only have to apply different linear/non-linear transformations.

Vectorized data has many advantages. It easy to calculate, manipulate and visualize. Because of these advantages, vectorizing document to do comparisons/search etc.Â Quantization also served us well those days. After quantization, it is almost straightforward to apply semi-naive Bayes / histogram etc.

There are several missing parts that worth to mention. We generally believe that human eyes have the function to vectorize what it perceives. But what level of vectorization have we gain is a bit little vague. Our current digital imaging technology forms a vector representation of image based on per-pixel intensity. Though there are similarities in low-level (eye function), human can more efficiently break image into higher/more compact representation. Let's assume it is still a vector representation, it should be weighted, dimension-reduced vector. An observation of human skimming skill suggests that human mayhave the ability to automatically verctorize document by skimming.
